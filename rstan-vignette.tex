\documentclass[12pt]{article}
\usepackage{Sweave}
\usepackage{hyperref}
\usepackage{times}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{xspace}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{url}
\usepackage{booktabs} 
\usepackage{enumerate}
\usepackage{alltt}
\usepackage{multirow}
\usepackage{makeidx}
\usepackage{verbatimbox}


\DefineVerbatimEnvironment{Sinput}{Verbatim} {xleftmargin=2em,fontsize=\footnotesize} 
\DefineVerbatimEnvironment{Soutput}{Verbatim}{xleftmargin=2em,fontsize=\footnotesize} 
\DefineVerbatimEnvironment{Scode}{Verbatim}{xleftmargin=2em,fontsize=\footnotesize}

\newcommand{\R}{R\xspace}
\newcommand{\Stan}{Stan\xspace}
\newcommand{\CmdStan}{CmdStan\xspace}
\newcommand{\RStan}{RStan\xspace}
\newcommand{\stanc}{{\ttfamily stanc}\xspace}
\newcommand*{\Cpp}{C\raise.2ex\hbox{\footnotesize ++}\xspace} %\ensuremath{++}
\newcommand{\clang}{{\ttfamily clang\raise.2ex\hbox{\footnotesize ++}}\xspace} 
\newcommand{\gpp}{{\ttfamily g\raise.2ex\hbox{\footnotesize ++}}\xspace} 
\newcommand{\clangpp}{{\ttfamily clang\raise.2ex\hbox{\footnotesize ++}}\xspace} 

\providecommand{\T}{\rule{0pt}{2.6ex}}
\providecommand{\B}{\rule[-1.2ex]{0pt}{0pt}}

\providecommand{\rstanfunidx}[1]{\index{\pkg{rstan} functions!#1}}
    
    \newcommand{\acronym}[1]{{\sc #1}\xspace}
      
      \newcommand{\ASCII}{\acronym{ascii}}
      \newcommand{\BNF}{\acronym{bnf}}
      \newcommand{\MATLAB}{\acronym{matlab}}
      \newcommand{\SPLUS}{\acronym{s}}
      \newcommand{\BUGS}{\acronym{bugs}}
      \newcommand{\JAGS}{\acronym{jags}}
      \newcommand{\MCMC}{\acronym{mcmc}}
      \newcommand{\HMC}{\acronym{hmc}}
      \newcommand{\NUTS}{\acronym{nuts}}
      \newcommand{\MSVC}{\acronym{msvc}}
      \newcommand{\LKJ}{\acronym{lkj}}
      \newcommand{\CPC}{\acronym{cpc}}
      
      \newcommand{\code}[1]{{\tt #1}}
        
        \newcommand{\strong}[1]{\texorpdfstring%
          {{\normalfont\fontseries{b}\selectfont #1}}%
            {#1}}
            \let\pkg=\strong
            \newcommand{\CRANpkg}[1]{\href{http://cran.r-project.org/package=#1}{\pkg{#1}}}%
              \let\cpkg=\CRANpkg
              \newcommand{\ctv}[1]{\href{http://CRAN.R-project.org/view=#1}{\emph{#1}}}
                \newenvironment{example}{\begin{alltt}}{\end{alltt}}
              \newenvironment{smallexample}{\begin{alltt}\small}{\end{alltt}}
              
              \newcommand{\E}{\mathsf{E}}
              \newcommand{\VAR}{\mathsf{VAR}}
              \newcommand{\COV}{\mathsf{COV}}
              \newcommand{\Prob}{\mathsf{P}}
              
              \bibliographystyle{apalike}
              
              %\VignetteIndexEntry{RStan} 
              
              % The next line is needed for inverse search...
\input{rstan-vignette-concordance}
              <<echo=false>>=
                options(width=80)
              library(rstan)
              @
                
                \title{\RStan: the \R interface to \Stan} 
              
              \author{The Stan Development Team \\ stan@mc-stan.org}
              \makeindex
              
              \begin{document}
              
              \maketitle
              
              \tableofcontents
              
              \begin{abstract}
              In this vignette we present the \RStan package \pkg{rstan} for using Stan in \R. 
              \Stan is a package for making Bayesian inferences using the No-U-Turn sampler (a 
                                                                                             variant of Hamiltonian Monte Carlo) or frequentist inference via optimization. We 
              illustrate the features of \RStan through an example in \cite{GelmanCarlinSternRubin:2003}.
              \end{abstract}
              
              
              \section{Introduction}
              
              \Stan is a \Cpp library for Bayesian modeling and inference
              that primarily uses the No-U-Turn sampler (NUTS) (\citealt{hoffman-gelman:2012})
              to obtain posterior simulation given user-specified model and data. Alternatively,
              \Stan can utilize the LBFGS optimization algorithm to maximize an objective function,
              such as a log-likelihood. The \R package, \pkg{rstan} allows one to conveniently 
              use \Stan from \R (\citealt{rprj}) and to access \Stan output, which includes
              posterior inferences and also intermediate quantities such as evaluation
              of the log posterior density and its gradients. 
              
              The website for \Stan and \RStan, \url{http://mc-stan.org},
              provides up-to-date information about how to operate \Stan and \RStan.
              For example, ``\RStan Getting Started'' (\citealt{rstangettingstarted2012})
              has a couple of examples.  The present article provides 
              a concise introduction to the functionality of package \pkg{rstan} and
              provides pointers to many functions in \pkg{rstan} from the user's perspective.
              
              We start with the prerequisites for using \pkg{rstan} 
              (section \ref{subsec0pre}) and a typical workflow of using \Stan
              and \RStan (section \ref{subsec0workflow}). 
              In section \ref{sec0example}, we  illustrate the process 
              of using \pkg{rstan} to estimate a Bayesian model.
              Section \ref{sec0moredetails} presents further details on \pkg{rstan}. 
              In section \ref{sec0workwstan}, we discuss some functions that \pkg{rstan}
              provides to access the results when \Stan is used from the command line. 
              
              \subsection{Prerequisites} 
              \label{subsec0pre}
              
              Users need to know how to specify statistical models 
              using the \Stan modeling language, which is detailed 
              in the manual of \Stan (\citealt{StanManual}).
              We give an example below. To do so, a \Cpp compiler is required, such as
              \gpp\footnote{\url{http://gcc.gnu.org}} or \clangpp\footnote{\url{http://clang.llvm.org}}.
              There are instructions on how to install a \Cpp compiler at 
              \url{https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started#prerequisites}.
              
              Package \pkg{rstan} depends on several other \R packages: 
              \begin{itemize}
              \item \cpkg{StanHeaders} which provides the \Stan \Cpp headers
              \item \cpkg{BH} which provides Boost \Cpp headers
              \item \cpkg{RcppEigen} which provides Eigen \Cpp headers
              \item \cpkg{Rcpp} which facilitates using \Cpp from \R
              \item \cpkg{inline} which compiles \Cpp for use with \R
              \end{itemize}
              
              These package dependencies should be automatically installed if you
              install the \pkg{rstan} package via one of the conventional mechanisms.
              
              \subsection[Typical workflow of using RStan]{Typical workflow of using RStan}
              \label{subsec0workflow}
              
              \Stan has a modeling language, which is similar to 
              but not identical to that of the Bayesian graphical modeling package 
              BUGS (\citealt{WinBUGS}). A parser translates the model expressed in the \Stan modeling 
              language to \Cpp code, whereupon it is compiled to an executable program and loaded as
              a Dynamic Shared Object (DSO) in \R and can be called by the user.
              In summary, the following are typical steps of using \Stan for Bayesian inference. 
              \begin{enumerate}[a.]\addtolength{\itemsep}{-0.6\baselineskip}
              \item Represent a statistical model by writing its log posterior
              density (up to an arbitrary normalizing constant that does not 
              depends on the unknown parameters in the model) using the \Stan modeling language.
              We recommend a separate text file for this, although it can be done using a
              character string within \R.
              \item Translate the model coded in \Stan modeling language to \Cpp code using the \stanc
              function (which is called by the \code{stan} function)
              \item Compile the \Cpp code for the model using a \Cpp compiler to
              create a DSO (also called a dynamic link library (DLL)) that can be loaded by \R
              (which is called by the \code{stan}).
              \item Run the DSO to sample from the posterior distribution using the 
              \code{stan} or \code{sampling} functions.
              \item Diagnose non-convergence of the MCMC chains
              \item Conduct inference based on the samples from the posterior distribution
              \end{enumerate}
              
              Steps c, d, and e above are all performed implicitly by a single call to \code{stan}.
              
              \section[An example of using rstan]{An example of using \pkg{rstan}}
              \label{sec0example} 
              
              In section 5.5 of \cite{GelmanCarlinSternRubin:2003}, a hierarchical model is
              used to model the effect of coaching programs on college admissions 
              tests.  The data, shown in Table~\ref{tab08schoolsdata}, summarize the results
              of experiments conducted in eight high schools, with an estimated standard 
              error for each, and these data and model are of historical interest as an example
              of full Bayesian inference (\citealt{Rubin1981}). 
              We use this example here for its simplicity and because it represents a nontrivial
              Markov chain simulation problem in that there is dependence between the parameters 
              of original interest in the study --- the effects of coaching in each of the eight 
              schools --- and the hyperparameter representing the variation of these effects in the 
              modeled population.  Certain implementations of a Gibbs sampler or a Hamiltonian 
              Monte Carlo sampler can be slow to converge in this example. 
              For short, we call this example ``eight schools.'' 
              The statistical model is specified as 
              \begin{align}
              y_j &\sim \text{normal}(\theta_j, \sigma_j), \quad j=1,\ldots,8 \\ 
              \theta_1, \ldots, \theta_8 &\sim \text{normal}(\mu, \tau), 
              \end{align} 
              in which each $\sigma_j$'s assumed known and a uniform prior 
              density is used, $p(\mu, \tau) \propto 1$. 
              
              \begin{table}
              \begin{center}\begin{tabular}{ccc}
              &\multicolumn{1}{c}{Estimated}&\multicolumn{1}{c}{Standard error}\\
              &\multicolumn{1}{c}{treatment}&\multicolumn{1}{c}{of effect}\\
              School&\multicolumn{1}{c}{effect, $y_j$}&
                \multicolumn{1}{c}{estimate, $\sigma_j$}\\\hline
              A& \ 28 & 15 \\
              B& \ \,\, 8 & 10 \\
              C& $\,-3$ & 16 \\
              D& \ \,\, 7 & 11 \\
              E& $\,-1$ & \ 9 \\
              F& \ \,\, 1 & 11 \\
              G& \ 18 & 10 \\
              H& \ 12 & 18
              \end{tabular}
              \end{center}
              \caption{Observed effects of coaching on college admissions test scores in
                eight schools.  We fit these data using a hierarchical model allowing variation
                between schools.}
              \label{tab08schoolsdata}
              \end{table}
              
              \subsection{Express the model in Stan}
              
              We first need to express this model in the \Stan modeling language. The \pkg{rstan} 
              package allows a model to be coded in a text file (typically with suffix \code{.stan}) 
              or in a \R character vector (of length one). 
              We put the following text into a file called schools.stan: 
                \begin{Schunk}
              \begin{Sinput}
              data {
                int<lower=0> J; // number of schools 
                real y[J];      // estimated treatment effects
                real<lower=0> sigma[J]; // s.e. of effect estimates 
              }
              parameters {
                real mu; 
                real<lower=0> tau;
                vector[J] eta;
              }
              transformed parameters {
                vector[J] theta;
                theta <- mu + tau * eta;
              }
              model {
                eta ~ normal(0, 1);
                y ~ normal(theta, sigma);
              }
              \end{Sinput}
              \end{Schunk}
              
              The first section of the above code specifies the data that is conditioned upon by
              Bayes Rule:  the number of schools, $J$; the vector of estimates, $y_1,\dots,y_J$; and 
              the standard errors, $\sigma_{1},\dots\sigma_{J}$.  Data are labeled as integer or real and
              can be vectors (or, more generally, arrays) if dimensions are specified.  Data
              can also be constrained; for example, in the above model $J$ has been
              restricted to be nonnegative and the components of $\sigma_y$ must all be positive.
              
              The next section of the code defines the parameters whose posterior distribution is sought
              using Bayes Rule. These are the their mean, $\mu$, and standard deviation, $\tau$, of the 
              school effects, plus the standardized school-level effects $\eta$. In this model, we let
              the undstandardized school-level effects, $\theta$, be a transformed parameter that uses
              $\mu$ and $\tau$ to shift and scale the standardized effects $\eta$ instead of
              directly declaring $\theta$ as a parameter. By parameterizing the model this way, the
              sampler runs more efficiently because the resulting multivariate geometry is more amendable
              to Hamiltonian Monte Carlo (\citealt{Neal:2011}).
              
              Finally, the model block looks similar to standard statistical notation.
              (Just be careful:  the second argument to Stan's normal$(\cdot,\cdot)$
              distribution is the standard deviation, not the variance as is usual in
              statistical notation.)  We have written the model in vector notation, which
              allows Stan to make use of more efficient algorithmic differentiation (AD).  It
              would also be possible --- but less efficient --- to write the model by
              replacing \verb+y ~ normal(theta,sigma);+ with a loop over the $J$ schools,
              \verb+for (j in 1:J) y[j] ~ normal(theta[j],sigma[j]);+\,.
              
              \Stan has versions of many of the most useful \R functions for statistical modeling, 
              including probability distributions, matrix operations, and special functions. However,
              the names of the \Stan functions may differ from their \R counterparts and more subtly,
              the parameterizations of probability distributions in \Stan may differ from those in \R
              for the same distribution. To mitigate this problem, the \code{lookup} function can be
              passed a \R function or character string naming an \R function, and \pkg{rstan} will 
              attempt to look up the corresponding \Stan function, display its arguments, and give
              the page number in \cite{StanManual} where the \Stan function is discussed.
              
              <<lookup, echo=TRUE>>=
              lookup("dnorm")
              tail(lookup("~")) # looks up all Stan sampling statements
              lookup(dwilcox)   # no corresponding Stan function
              @
              
              If the \code{lookup} function fails to find an R function that corresponds to a 
              Stan function, it will treat its argument as a regular expression and attempt to
              find matches with the names of Stan functions.
              
              \subsection{User-defined Stan functions}
              
              \Stan permits users to define their own functions in a functions block of a \Stan
              program. The functions block is optional but if it exists, it must come before any
              other block. This mechanism allows users to implement statistical distributions or
              other functionality that is not currently available in \Stan. However, even if the
              user's function merely wraps calls to existing \Stan functions, the code in the model
              block can be much more readible if several lines of \Stan code that accomplish one
              (or perhaps two) task(s) are replaced by a call to a user-defined function.
              
              Another reason to utilize user-defined functions is that \pkg{rstan} provides an \\ 
              \code{expose\_stan\_functions} function that exports such functions to the \R global environment so
              that they can be tested in \R to ensure that they are working properly. For example,
              
              <<expose_stan_functions, echo=TRUE>>=
                model_code <-
                '
              functions {
              real standard_normal_rng() {
              return normal_rng(0,1);
              }
              }
              model {}
              '
              expose_stan_functions(stanc(model_code = model_code))
              standard_normal_rng(seed = 1)
              @
                
                
                \subsection{Preparing the data}
              
              The \code{stan} function in \pkg{rstan} accepts data as a \code{list} or an \code{environment}.
              Alternatively the \code{data} argument can be omitted and \R will search for objects that
              have the same names as in the \code{data} block of a Stan program.
              To prepare the data in \R, we create a \code{list} as follows. 
              <<echo=TRUE>>=
                schools_data <- 
                list(J=8, 
                     y=c(28,  8, -3,  7, -1,  1, 18, 12),
                     sigma=c(15, 10, 16, 11,  9, 11, 10, 18))
              @
                
                It would also be possible (indeed, encouraged) to read in the data
              from a file rather than to directly enter 
              the numbers in the \R script. 
              
              \subsection{Sample from the posterior distribution}
              \label{subsec0stansampling}
              
              Next, we can call the \code{stan} function to draw posterior samples:
                <<callstan, echo=TRUE, results=hide, cache=TRUE>>=
                J <- 8
              y <- c(28,  8, -3,  7, -1,  1, 18, 12)
              sigma <- c(15, 10, 16, 11,  9, 11, 10, 18)
              
              fit1 <- stan(file="schools.stan", 
                           # better to add explicitly include: data=schools_data, 
                           iter=2000, chains=4, cores=2)
              @
                
                Function \code{stan} wraps the following three steps: 
                \begin{enumerate}[a.]\addtolength{\itemsep}{-0.6\baselineskip}
              \item Translate a model in \Stan code to \Cpp code 
              \item Compile the \Cpp code to a dynamic shared object (DSO) and load the DSO
              \item Sample given some user-specified data and other settings
              \end{enumerate}
              
              A single call to \code{stan} performs all three steps, but they can also be  
              executed one by one, which can be useful for debugging.   In addition, \Stan
              saves the DSO so that when the same model is fit again (possibly with new
                                                                      data), function \code{stan} can be called so that only the third step is performed, thus
              saving compile time.
              
              Function \code{stan} returns an object of S4\footnote{For those who are not familiar 
                with the concept of class and S4 class in \R, refer to \cite{chambers2010software}. 
                A S4 class consists of some attributes (data) to model an object and 
                some methods to model the behavior of the object. From a user's perspective,  
                once a \code{stanfit} object is created, we are mainly concerned about what methods 
                are defined for the \code{stanfit}.} class \code{stanfit}.
                If no error occurs, the returned \code{stanfit} 
                object includes the samples drawn from the posterior distribution for the 
                model parameters and other quantities defined in the model. 
                If there is an error (for example, when we have syntax error in our \Stan code),
                \code{stan} will either quit or return a \code{stanfit} object that contains no
                samples. Including the DSO as part of a \code{stanfit} object
                allows it to be reused so that compiling the same model could be avoided when
                we want to sample again with the same or different input of data and other settings.
                Also if an error happens after the model is compiled but before sampling (for
                example, problems with input such as data and initial values),
                we can reuse the previous compiled model. 
                For class \code{stanfit}, many methods such as \code{print} and \code{plot} 
                are defined to work with the samples and conduct model inference. For example, 
                the following shows a summary of the parameters for our
                example using function \code{print}.
                <<echo=TRUE>>=
                print(fit1, pars=c("theta", "mu", "tau", "lp__"), 
                probs=c(.1,.5,.9))
                @
                
                The last line of this output, {\tt lp\_\_}, is the logarithm of the
                (unnormalized) posterior density as calculated by \Stan.  This log density can be used 
                in various ways for model evaluation and comparison (see, e.g., \citealt{Vehtari2012}).
                %Vehtari, A., and Ojanen, J. (2012). A survey of Bayesian predictive methods
                %for model assessment, selection and comparison. 
                %Statistics Surveys 6, 142-228. 
                
                
                \section[Advanced features]{Advanced features}
                \label{sec0moredetails}
                
                In this section, we discuss more details and other advanced 
                features of \pkg{rstan}. The details pertain to the optional
                arguments of the \code{stan} function, data preprocessing, and methods for the
                S4 class \code{stanfit}. In addition, we discuss optimization, which can be 
                used to obtain a point estimates via \Stan. 
                
                \subsection[Arguments to the \code{stan} function]{Arguments to the \code{stan} function} 
                
                The primary arguments for sampling (in function \code{stan} and 
                \code{sampling}) include data, initial values, and the options of the 
                sampler such as \code{chains}, \code{iter}, and \code{warmup}.
                In particular, \code{warmup} specifies the number of iterations 
                that are used by NUTS sampler for the adaptation phase before sampling begins.
                After the warmup, the sampler turns off adaptation and continues until a total of 
                \code{iter} iterations have been completed.
                There is no theoretical guarantee that the samples are drawn from the posterior distribution 
                during warmup, so the warmup samples should only be used for diagnosis and not for
                inference.  The summaries for the parameters shown by the \code{print} method
                are calculated using only the samples after warmup.
                
                For function \code{stan}, argument \code{init} is used for specifying
                the initial values.  There are several options for \code{init} and the 
                details can be found in the documentation of the \code{stan} function. The vast majority
                of the time, it is adequate to allow \Stan to generate its own initial values randomly.
                However, sometimes it is better to specify the initial values for at least a subset
                of the objects declared in the \code{parameters} block of a Stan program.
                
                \Stan uses a random number generator (RNG) that supports parallelism.
                The initialization of the RNG is determined by arguments \code{seed}
                and \code{chain\_id}.  Even if we are running multiple chains from one call to the \code{stan}, 
                function we only need to specify one seed, which is randomly generated by \R if not specified.
                
                \subsection{Data preprocessing and passing}
                
                The data passed to \code{stan} will go through a preprocessing procedure. 
                The details of this preprocessing are documented in the help 
                for function \code{stan}. Here we stress a few important steps.  
                First, \pkg{rstan} allows the user to specify more than what is declared in the data block
                and anything beyond that is silently omitted. In general, an element in the input \R list should 
                be numeric data and its dimension should match the declaration in the data block of the model.
                So for example, \code{factor} type in \R is not supported as data element for \RStan and must
                be converted to integer codes via \code{as.integer()}. The \Stan modeling language 
                distinguishes between integers and doubles (type \code{int} and \code{real} in Stan modeling language, 
                respectively). The \code{stan} function will convert some R data (which is double-precision usually) to 
                \code{integer}s if possible.
                
                In \Stan, we have scalars and other types that are a set of scalars, such as vectors and matrices. 
                As \R does not have scalars, \pkg{rstan} treats vectors of length one as scalars.
                However, we might have a model with data block defined as in Figure~\ref{fig0datablock}, 
                in which $N$ can be $1$ as a special case.
                So if we know that $N$ is always larger than $1$, we can use a vector of length $N$ in \R
                as the data input for $y$ (for example, a vector created by ``\code{y <- rnorm(N)}''). 
                If we want to prevent \pkg{rstan} from treating the input data for $y$ as a scalar when $N=1$,
                we need to explicitly make it an array as the following \R code shows.
                
                <<echo=TRUE>>=
                y <- as.array(y)
                @
                
                
                \begin{verbbox}
                
                data {                
                int<lower=0> N;      
                real y[N];
                } 
                
                \end{verbbox} 
                
                \begin{figure}[hb]
                \centering
                \frame{
                \theverbbox
                }
                \caption{Data block of an example model in \Stan code}
                \label{fig0datablock} 
                \end{figure}
                
                
                As Stan cannot handle missing values in data automatically, so no element of
                the data can contain \code{NA} in \R. An important step in \pkg{rstan}'s data
                preprocessing is to check missing values and issue an error if any. To model
                missing values using \Stan, you should create binary indicators of whether
                a data point is observed or missing and then change the \code{NA} values in \R
                to valid numbers before calling \code{stan}.
                
                \subsection[Methods for the \code{stanfit} class]{Methods for the \code{stanfit} class} 
                
                For the fitted object that is an instance of the S4 class \code{stanfit}, we have 
                defined methods such as \code{print}, \code{summary}, \code{plot}, \code{pairs}, and 
                \code{traceplot}.  We can use these methods to assess the convergence of the Markov chains 
                by looking at the trace plots and calculating the split $\hat{R}$.\footnote{Split
                  $\hat{R}$ is an updated version of $\hat{R}$ statistic proposed in
                  \cite{GelmanRubin:1992} that is based on splitting each chain
                  into two halves. See the \Stan manual for more details.} %
                The \code{print} method outputs the mean, standard deviation, quantiles of interest, split
                $\hat{R}$, and effective sample size for each unknown quantity over all the chains combined.
                
                The \code{plot}\rstanfunidx{plot} method provides an overview of the output, while the
                \code{pairs} method shows two-dimensional density plots for each pair of unknown quantities
                that are stratified according to the \code{condition} argument. The 
                \code{traceplot}\rstanfunidx{traceplot} method plots the traces of all chains for the specified
                parameters. If we include the warmup draws by setting \code{inc\_warmup=TRUE} (the 
                                                                                               default), the background color of the warmup area is different from the post-warmup phase.   
                
                Figure~\ref{fig0stanfitplot} presents the plot of the eight schools example. 
                In this plot, credible intervals (by default 80\%) for all the parameters
                as well as \code{lp\_\_} (the log of posterior density function up to an additive
                                          constant), and the median of each chain are displayed. In addition, under the lines
                representing intervals, small colored areas are used to indicate which range the 
                value of the split $\hat{R}$ statistic is in. Figure~\ref{fig0stanfittraceplot} shows the
                traceplot for the $\tau$ parameter.
                
                \begin{figure}[ht]
                \centering
                <<echo=false, fig=TRUE, label=stanfit_plot>>=
                  plot(fit1)
                @
                  \caption{An overview plot for eight schools example} 
                \label{fig0stanfitplot}
                \end{figure}
                
                \begin{figure}[ht]
                \centering
                <<echo=false, fig=TRUE, label=stanfit_tplot, height=4, width=6>>=
                  traceplot(fit1, pars = "tau")
                @
                  \caption{Trace plots of $\tau$ in the eight schools model} 
                \label{fig0stanfittraceplot}
                \end{figure}
                
                The \code{stanfit} class has a set of methods to work with the samples drawn 
                from the posterior distribution. First, the \code{extract}\rstanfunidx{extract} 
                method provides different ways to access the samples. If the argument \code{permuted} 
                is \code{TRUE}, then the samples after warmup are returned in an permuted order as a 
                list, each element of which are the samples for a parameter. Here by ``one parameter'', 
                we mean a scalar/vector/array parameter as a whole defined in the parameters block, 
                transformed parameters block, or generated quantities block of our Stan program. In the 
                eight schools example, $\theta$ is one parameter though it is an array of length $J$. 
                
                If \code{permuted=FALSE}, the result depends on the \code{inc\_warmup} argument.
                In either case, the returned object is an array with the first dimension indicating
                iterations, the second indicating chains, and the third indicating parameters. If
                \code{inc\_warmup=TRUE}, all iterations are included and if \code{inc\_warmup=FALSE},
                only the post-warmup iterations are included. The latter is appropriate for inference,
                while the former may be useful for diagnosis. In the returned array, each
                vector/array parameter is ``flattened'' and are included as the third dimension of
                the array. In our eight schools examples, the third dimension is \code{theta[1]}, 
                \ldots, \code{theta[8]}.
                <<echo=TRUE>>=
                  s <- extract(fit1, pars = c("theta", "mu"), permuted = TRUE)
                names(s)
                dim(s$theta)
                dim(s$mu)
                s2 <- extract(fit1, pars = "theta", permuted = FALSE)
                dim(s2)
                dimnames(s2)
                @
                  
                  In addition, the \code{as.array}\rstanfunidx{as.array}, \code{as.matrix}\rstanfunidx{as.matrix}, and
                \code{as.data.frame}\rstanfunidx{as.data.frame} methods are defined for \code{stanfit} object. These
                method return the draws of samples in forms of a 3-dimension array, matrix (\code{rbind}ing the chains), 
                or \code{data.frame} (that is coerced from a matrix). There are also 
                \code{dimnames}\rstanfunidx{dimnames} and \code{names}\rstanfunidx{names} methods for \code{stanfit}
                objects.
                
                A \code{stanfit} object keeps all the information regarding the sampling
                procedure, for example, the model in \Stan code, the initial
                values for all parameters, the seed for the RNG,
                and parameters used for the sampler (for example, the step size for NUTS) 
                The following methods
                \begin{enumerate}
                \item \code{get\_seed}\rstanfunidx{get\_seed}
                \item \code{get\_inits}\rstanfunidx{get\_inits}
                \item \code{get\_adaptation\_info}\rstanfunidx{get\_adaptation\_info}
                \item \code{get\_sampler\_params}\rstanfunidx{get\_sampler\_params}
                \end{enumerate}
                for shown in Table~\ref{tab0stanfitfuns} along with other methods defined for the \code{stanfit} class.
                
                Last, a common feature for many methods that are defined for the \code{stanfit} class is that 
                the \code{pars} argument can be specified to indicate a subset of the parameters.  This
                feature is helpful when there are too many parameters in the model or when we need to reduce memory usage. 
                For instance, in the eight schools example, we have parameter $\theta$ defined as
                ``\code{real theta[J]}''. So we can specify
                \code{pars="theta"} or \code{pars="theta[1]"}.
                However, specifying part of $\theta$ (i.e., \code{pars="theta[1:2]"}) as in \R
                is not allowed --- a workaround for this is to specify \code{pars=c("theta[1]","theta[2]")}. 
                The \code{stan} function allows the user to specify \code{pars} so that only part of 
                the samples are returned, which might be problematic from the perspective of
                diagnosing MCMC convergence since we would apply our diagnostic criterion to a subset
                of our parameters. To mitigate this loss of diagnostics information, we can
                use the \code{get\_posterior\_mean}\rstanfunidx{get\_posterior\_mean} function,
                which returns the posterior mean of all parameters for each chain and all chains combined
                (excluding warmup samples). Another alternative is to write the samples to external files 
                using the \code{sample\_file} argument of the \code{stan} function and then conduct diagnostics
                with the external files.
                
                \subsection{Sampling difficulties} 
                
                The best way to visualize the output of a model is through the \pkg{shinyStan} package,
                which is currently only available from \url{https://github.com/stan-dev/shinystan}.
                The \pkg{shinyStan} package facilitates both the visualization of parameter distributions
                and diagnosing problems with a sampler. 
                
                However, it is also possible to diagnose problems with a sampler directly
                via the \code{get\_sampler\_params} function.
                <<echo=TRUE>>=
                  # all chains combined
                  summary(do.call(rbind, args = get_sampler_params(fit1, inc_warmup = TRUE)),
                          digits = 2)
                # each chain separately
                lapply(get_sampler_params(fit1, inc_warmup = TRUE), summary, digits = 2)
                @
                  Here we see that there are a small number of divergent transitions, which are identified
                by \code{n\_divergent\_\_} being 1. Ideally, there should be no divergent transitions
                after the warmup phase. The best way to try to eliminate divergent transitions is by
                increasing the target acceptance probability, which by default is $0.8$. Here we see
                that the mean of \code{accept\_stat\_\_} is close to $0.8$ for all chains, but has
                a very skewed distribution because the median is near $0.95$. We could go back and
                call \code{stan} again and specify the optional argument 
                \code{control = list(adapt\_delta = 0.9)} to eliminate the divergent transitions.
                However, sometimes when the target acceptance rate is high, the stepsize is very
                small and the sampler hits its limit on the number of leapfrog steps it can take
                per iteration. In this case, it is a non-issue because each chain has a
                \code{treedepth\_\_} of at most $7$ and the default is $10$. But if any 
                \code{treedepth\_\_} were $11$, then it would be wise to increase the limit by
                passing \code{control = list(max\_treedepth = 12)} (for example) to \code{stan}.
                
                \begin{figure}[ht]
                \centering
                <<echo=false, fig=TRUE, label=pairs_plot, height=4, width=6>>=
                  pairs(fit1, pars = c("eta", "theta"), include = FALSE, las = 1)
                @
                  \caption{Pairs plots of the common parameters in the eight schools model}
                \label{fig0pairsplot}
                \end{figure}
                
                Figure~\ref{fig0pairsplot} gives a graphical representation of the same information.
                The marginal distribution of each indicated parameter is included as a histogram.
                By default, draws with below-median \code{accept\_stat\_\_} are plotted below the
                diagonal and those with above-median \code{accept\_stat\_\_} are plotted above the
                diagonal. Each off-diagonal square represents a bivariate distribution of the draws for the 
                intersection of the row-variable and the column-variable. Ideally, the below-diagonal
                intersection and the above-diagonal intersection of the same two variables should
                have distributions that are mirror images of each other. Any yellow points would indicate
                transitions where the maximum \code{treedepth\_\_} was hit, and the red points indicate
                a transition where \code{n\_divergent\_\_ = 1}. Thus, the pairs plot should be used
                to get a sense of whether any sampling difficulties are occurring in the tails or
                near the mode.
                
                \subsection{The log posterior function and its gradient} 
                
                Essentially, we define the log of the probability
                density function of a posterior distribution up to an unknown additive constant.
                In \Stan, we use \code{lp\_\_} to represent the realizations of this log kernel at 
                each iteration.   In \pkg{rstan}, \code{lp\_\_} is treated as an unknown
                in the summary and the calculation of split $\hat{R}$ and effective sample size.
                
                A nice feature of \pkg{rstan} is that functions for calculating \code{lp\_\_}
                and its gradients for a \code{stanfit} object are exposed. They are defined
                for a \code{stanfit} object, since we need data to create a model instance. 
                These two functions are \code{log\_prob}\rstanfunidx{log\_prob}
                and \code{grad\_log\_prob}\rstanfunidx{grad\_log\_prob} respectively. Both take parameters
                on the \textit{unconstrained} space, even if the support of a parameter 
                is not the whole real line. See \cite{StanManual} for more details
                about transformations from the entire real line to some subspace of it. Also the number of 
                unconstrained parameters might be less than the number of parameters. For example, when
                a parameter is a simplex of length $K$, the number of unconstrained parameters are $K-1$ 
                  due to the constraint that all elements of a simplex must be nonnegative and sum to one.
                The \code{get\_num\_upars}\rstanfunidx{get\_num\_upars} method is provided to get the number 
                of unconstrained parameters, while the \code{unconstrained\_pars}\rstanfunidx{unconstrained\_pars} 
                and \code{constrained\_pars}\rstanfunidx{constrained\_pars} methods can be used to unconstrain
                or constrain parameters respectively. The former takes a list of parameters as input and transforms it 
                to an unconstrained vector, and the latter does the opposite. Using these functions, we can implement 
                other algorithms such as maximum a posteriori estimation of Bayesian models.
                
                \begin{table}
                \begin{tabular}{lp{0.6\linewidth}} 
                \toprule 
                Name  &    Function    \\ 
                \midrule
                \code{print}         & print the summary for parameters obtained using all chains  \\
                \code{summary}       & summarize the sample from all chains and individual chains for parameters \\
                \code{plot}          & plot the inferences (intervals, medians, split $\hat{R}$) for parameters \\
                \code{traceplot}     & plot the traces of chains  \\
                \code{pairs} & make a matrix of scatter plots for the samples of parameters  \\
                \code{extract}       & extract samples of parameters  \\
                \code{get\_stancode}     & extract the model code in \Stan modeling language \\
                \code{get\_stanmodel}     & extract the \code{stanmodel} object \\ 
                \code{get\_seed}      & get the seed used for sampling  \\
                \code{get\_inits}     & get the initial values used for sampling  \\
                \code{get\_posterior\_mean}     & get the posterior mean for all parameters\\
                \code{get\_logposterior}     & get the log posterior (that is, \code{lp\_\_})  \\
                \code{get\_sampler\_params}    & get parameters used by the sampler such as \code{treedepth} of NUTS  \\
                \code{get\_adaptation\_info}    & get adaptation information of the sampler \\ 
                \code{get\_num\_upars}    & get the number of parameters on unconstrained space \\ 
                \code{unconstrain\_pars}    & transform parameter to unconstrained space \\ 
                \code{constrain\_pars}    & transform parameter from unconstrained space to its defined space \\
                \code{log\_prob}    & evaluate the log posterior for parameter on unconstrained space \\
                \code{grad\_log\_prob}    & evaluate the gradient of the log posterior for parameter on unconstrained space \\
                \code{as.array}        & \multirow{3}{\linewidth}{extract the samples excluding warmup to a three dimension array, matrix, data.frame}  \\
                \code{as.matrix}       & \\
                \code{as.data.frame}   & \\
                \code{dimnames}        & obtain the dimension names of the object in its array representation\\
                \code{names}           & obtain the ``flattened'' parameter names\\
                \bottomrule 
                \end{tabular}
                \caption[Methods for the S4 class stanfit]{Methods for the S4 class \code{stanfit}} 
                \label{tab0stanfitfuns} 
                \end{table}
                
                \subsection[Optimization in Stan]{Optimization in \Stan}
                \label{subsecoptimization}
                
                \RStan also provides an interface to \Stan's optimizers, which can be used
                to obtain a point estimate by maximizing the (perhaps penalized) likelihood 
                function defined by a Stan program. We illustrate the feature using a very simple
                example, estimating the mean from samples assumed to be drawn from normal 
                distribution with known standard deviation. That is, we assume 
                
                \begin{align*}
                y_1,\ldots,y_n\sim \text{normal}(\mu,1).
                \end{align*}
                
                By specifying prior of $\mu$ with $p(\mu) \propto 1$, the maximum a posteriori estimator 
                for $\mu$ is just the sample mean. The following \R code shows 
                how to use \Stan's optimizers in \pkg{rstan}; we first create a \code{stanmodel}
                object of \pkg{rstan} and then use its \code{optimizing} method, to which data 
                and other arguments can be fed.
                
                <<optimizer, echo=TRUE>>= 
                  ocode <- "
                data {
                int<lower=1> N;
                real y[N];
                } 
                parameters {
                real mu;
                } 
                model {
                y ~ normal(mu, 1);
                } 
                "
                
                sm <- stan_model(model_code = ocode)
                y2 <- rnorm(20)
                mean(y2)
                op <- optimizing(sm, data = list(y = y2, N = length(y2)), hessian = TRUE)
                print(op)
                @
                  
                  
                  \subsection[Model compiling in rstan]{Model compiling in \pkg{rstan}}
                \label{subsecmodelcompiling}
                
                In \RStan, for every model, we use function \code{stanc} to translate the 
                model from Stan modeling language code to \Cpp code 
                and then compile the \Cpp code to dynamic shared object (DSO),
                which is loaded by \R and executed to draw sample. 
                The process of compiling \Cpp code to DSO, sometimes, takes a while. 
                When the model is the same, we could reuse the DSO from previous run. 
                In function \code{stan}, if parameter \code{fit} is specified
                with a previous fitted object, the compiled model is reused. 
                When reusing a previous fitted model, we can specify different 
                data and other parameters for function \code{stan}. 
                
                In addition, if fitted models (objects in our working space of \R)
                are saved, for example, by \R function
                \code{save} and \code{save.image}, \pkg{rstan} is able to save the 
                DSO for models, so that they can be used across \R sessions. 
                To (not) save the DSO, specify the \code{save\_dso} argument, which
                is \code{TRUE} by default, in the \code{stan} function.
                
                If the user executes \code{rstan\_options(auto\_write = TRUE)}, then
                a serialized version of the compiled model will be automatically
                saved to the hard disk in the same directory as the .stan file or
                in \R's temporary directory if the Stan program is expressed as 
                a character string. Although this option is not enabled by default
                due to CRAN policy, it should ordinarily be specified by users in
                order to eliminate redundant compilation.
                
                \Stan runs much faster when the code is compiled at the maximum level of
                optimization, which is \code{-O3} on most \Cpp compilers. However, the
                default value is \code{-O2} in \R, which is appropriate for most \R
                packages but entails a slight slowdown for \Stan. You can change this
                default locally by following the instructions at 
                \url{http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Customizing-package-compilation}.
                However, you should be advised that setting \code{CXXFLAGS = -O3} may
                cause adverse side effects for other \R packages.
                
                \subsection{Run multiple chains in parallel}
                \label{sec0parallel}
                
                For function \code{stan}, we can specify the number of chains using the \code{chains} argument.
                By default, the chains are executed serially (i.e., one at a time) using the parent
                \R process. There is a \code{cores} argument to \code{stan} and \code{sampling}
                that can be set to the number of chains (if the hardware has sufficient processors and RAM),
                which is appropriate on most laptops. We ordinarily recommend first calling
                \code{options(mc.cores = parallel::detectCores())} once per R session so that
                \code{stan} and \code{sampling} can utilize all available cores.
                
                If you are using another parallelization scheme (perhaps with a remote cluster)
                \pkg{rstan} provides a function called \code{sflist2stanfit}\rstanfunidx{sflist2stanfit} that
                consolidates a list of multiple \code{stanfit} objects (sampled from one model with
                the same number of warmup and iteration) into one \code{stanfit} object. 
                It is important to specify the same seed for all the chains
                and equally important to use a different chain ID (argument \code{chain\_id}). This ensures
                that the random numbers generated in \Stan for all chains are essentially independent. 
                This part is handled automatically by \pkg{rstan} if \code{cores > 1}.
                
                \section[Working with CmdStan]{Working with \CmdStan} 
                \label{sec0workwstan}
                
                RStan provides some functions to help use \Stan from the command line, \CmdStan.
                First, when \Stan reads data or initial
                values, it supports a subset of the syntax of \R dump data formats.  
                So if we use \code{dump} function in \R to prepare data, \Stan
                might not be able to read the data. The \code{stan\_rdump} function in \pkg{rstan} 
                dumps the data from \R to a format that is supported by \Stan with symantics that are very 
                similar to the \code{dump} function in \R.
                
                Second, the \code{read\_stan\_csv}\rstanfunidx{read\_stan\_csv} function 
                in \pkg{rstan} creates a \code{stanfit} object from reading the comma separated
                files (CSV) generated by \CmdStan. As a result, we can use any methods
                defined for the \code{stanfit} class to diagnose and analyze the samples.
                
                \section{Summary} 
                \label{sec0summary}
                
                In this vignette, we have described the main functionality of RStan
                from a user's perspective. The help pages with the \pkg{rstan} package provide more details
                for all exposed \pkg{rstan} functions. The \Stan manual (\citealt{StanManual}) provides 
                many details and includes a variety of model examples, many of which are can be executed
                via function \code{stan\_demo} in the \pkg{rstan} package. Finally, the \pkg{loo} package,
                which is on CRAN, is very useful for model comparison using \code{stanfit} objects.
                
                \nocite{*} 
                \bibliography{rstan} 
                
                \printindex
                
                \end{document} 
                
